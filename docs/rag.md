# ğŸ’¬ RAG Querying

LaunchLens includes a lightweight Retrieval-Augmented Generation (RAG) module, enabling users to ask natural language questions about the launch dataset.

This system combines ChromaDB, OpenAI, and LangChain to deliver grounded, context-aware answers.

---

## ğŸ“š What Gets Indexed?

After analysis, the following files are embedded:

- `launch_recommendation.md`
- `top_launchpad_configs.csv`
- `orbit_mass_profiles.csv`
- `success_by_year.csv`

These represent statistical summaries and insights derived from the launch data.

---

## ğŸ”§ How It Works

1. **Document Loading**  
   Text and CSV files are parsed and chunked into semantic blocks using LangChainâ€™s text splitter.

2. **Embedding**  
   OpenAIâ€™s `text-embedding-ada-002` is used to convert each chunk into a vector.

3. **Storage**  
   All embeddings are stored in a local persistent ChromaDB directory (`chroma_store/`).

4. **Retrieval + Answering**  
   At query time, the top `k` relevant chunks are retrieved and passed to `ChatOpenAI`, which synthesizes a final answer.

---

## ğŸ” Environment Setup

To enable RAG, add your OpenAI key to a `.env` file in the project root:

```env
OPENAI_API_KEY=sk-...
```

## ğŸ§  Streamlit Integration

In the "Strategic Launch Planner" tab, users can:

- Ask questions like:
  - â€œWhatâ€™s the best orbit and payload for success?â€
  - â€œWhich launchpad has the highest success rate?â€
- View answers in real time, generated by an LLM grounded in LaunchLens analysis outputs

If no `.env` file is present with a valid OpenAI API key, the feature is gracefully hidden from the interface.


## ğŸ§© Modular by Design

The RAG functionality in LaunchLens is fully modular and lives in the `rag/` directory:

- `indexer.py`: Embeds and stores analysis outputs into ChromaDB after the pipeline runs
- `query_engine.py`: Provides a simple interface to query those embeddings using OpenAI and LangChain

This design keeps RAG isolated from core ETL and modeling logic, allowing teams to opt-in or extend it independently.
